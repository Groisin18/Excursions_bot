"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–±–æ—Ä—â–∏–∫ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º–∏
–í–∫–ª—é—á–∞–µ—Ç: –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞, —É–º–Ω–æ–µ –æ–±—Ä–µ–∑–∞–Ω–∏–µ –∫–æ–¥–∞, –∫–∞—Ä—Ç—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
"""
import re
import ast
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Tuple, Set, Optional

class ProjectAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–µ–∫—Ç –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π –æ —Å–±–æ—Ä–∫–µ"""

    def __init__(self, root_dir: Path):
        self.root_dir = root_dir
        self.stats = {
            "total_files": 0,
            "total_size": 0,
            "total_code_lines": 0,
            "python_files_count": 0,
            "file_types": defaultdict(int),
            "largest_files": [],  # –ü–æ —Ä–∞–∑–º–µ—Ä—É —Ñ–∞–π–ª–æ–≤
            "files_most_lines": [],  # –ü–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞
            "entry_points": [],
            "has_requirements": False,
            "has_setup": False,
            "framework": "generic",
            "complexity_score": 0
        }

    def analyze(self) -> Dict:
        """–ü—Ä–æ–≤–æ–¥–∏—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞, –∏—Å–∫–ª—é—á–∞—è —Å–±–æ—Ä—â–∏–∫"""
        print("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø—Ä–æ–µ–∫—Ç...")

        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ —Å–±–æ—Ä—â–∏–∫—É –∏–∑ –≤—ã–∑—ã–≤–∞—é—â–µ–≥–æ –∫–æ–¥–∞
        import inspect
        caller_frame = inspect.currentframe().f_back
        if caller_frame and 'self' in caller_frame.f_locals:
            collector = caller_frame.f_locals['self']
            if hasattr(collector, 'collector_path'):
                self.collector_path = collector.collector_path

        # –°–∫–∞–Ω–∏—Ä—É–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
        all_files = []
        total_code_lines = 0  # –°—á–µ—Ç—á–∏–∫ —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞ (–±–µ–∑ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫)

        for path in self.root_dir.rglob("*"):
            if path.is_file():
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                if any(excl in str(path) for excl in ["__pycache__", ".git", "venv", ".venv"]):
                    continue

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã —Å–±–æ—Ä—â–∏–∫–∞
                if hasattr(self, 'collector_path') and path.resolve() == self.collector_path:
                    continue

                rel_path = path.relative_to(self.root_dir)
                is_python_file = path.suffix.lower() == '.py'

                file_info = {
                    "path": rel_path,
                    "full_path": path,
                    "size": path.stat().st_size,
                    "suffix": path.suffix.lower(),
                    "is_python": is_python_file,
                    "code_lines": 0
                }
                all_files.append(file_info)

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                self.stats["total_files"] += 1
                self.stats["total_size"] += file_info["size"]
                self.stats["file_types"][file_info["suffix"]] += 1

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—Å–æ–±—ã–µ —Ñ–∞–π–ª—ã
                if file_info["path"].name in ["requirements.txt", "setup.py", "pyproject.toml"]:
                    if "requirements" in file_info["path"].name:
                        self.stats["has_requirements"] = True
                    if "setup" in file_info["path"].name or "pyproject" in file_info["path"].name:
                        self.stats["has_setup"] = True

                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è Python —Ñ–∞–π–ª–æ–≤
                if is_python_file:
                    try:
                        with open(path, 'r', encoding='utf-8') as f:
                            file_code_lines = 0
                            for line in f:
                                stripped_line = line.strip()
                                # –°—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                                if stripped_line:
                                    file_code_lines += 1

                            file_info["code_lines"] = file_code_lines
                            total_code_lines += file_code_lines

                            # –ú–æ–∂–Ω–æ —Ç–∞–∫–∂–µ –¥–æ–±–∞–≤–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫–∞—Ö
                            file_info["empty_lines"] = file_info["lines"] - file_code_lines if "lines" in file_info else 0

                    except (UnicodeDecodeError, PermissionError, OSError):
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã –±–µ–∑ –¥–æ—Å—Ç—É–ø–∞
                        pass

        # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–µ –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã (–ø–æ —Ä–∞–∑–º–µ—Ä—É)
        all_files.sort(key=lambda x: x["size"], reverse=True)
        self.stats["largest_files"] = all_files[:10]

        # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª—ã —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞
        python_files = [f for f in all_files if f["is_python"]]
        python_files.sort(key=lambda x: x.get("code_lines", 0), reverse=True)
        self.stats["files_most_lines"] = [
            {"path": str(f["path"]), "lines": f["code_lines"]}
            for f in python_files[:10]
        ]

        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ Python –∫–æ–¥–∞ –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats["total_code_lines"] = total_code_lines
        self.stats["python_files_count"] = len(python_files)

        # –ù–∞—Ö–æ–¥–∏–º —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞
        self._find_entry_points(all_files)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ—Ä–µ–π–º–≤–æ—Ä–∫
        self._detect_framework(all_files)

        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å (–º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞ –∫–∞–∫ –º–µ—Ç—Ä–∏–∫—É)
        self._calculate_complexity(all_files)

        # –°—Ç—Ä–æ–∏–º –¥–µ—Ä–µ–≤–æ –ø—Ä–æ–µ–∫—Ç–∞
        self._build_project_tree()

        print(f"üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {self.stats['total_files']} —Ñ–∞–π–ª–æ–≤, "
            f"{self.stats['total_size']/1024:.1f} KB, "
            f"{total_code_lines} —Å—Ç—Ä–æ–∫ Python –∫–æ–¥–∞ –≤ {self.stats['python_files_count']} —Ñ–∞–π–ª–∞—Ö")
        return self.stats

    def _find_entry_points(self, files: List[Dict]) -> None:
        """–ù–∞—Ö–æ–¥–∏—Ç —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞ –≤ –ø—Ä–æ–µ–∫—Ç"""
        entry_patterns = [
            ("main.py", 10),  # main.py —Å –≤—ã—Å–æ–∫–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
            ("app.py", 9),
            ("run.py", 8),
            ("manage.py", 7),
            ("wsgi.py", 6),
            ("asgi.py", 6),
            ("__main__.py", 5),
            ("server.py", 4),
            ("start.py", 3),
        ]

        entry_files = []
        for file_info in files:
            if file_info["is_python"]:
                filename = file_info["path"].name
                for pattern, score in entry_patterns:
                    if filename == pattern:
                        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ if __name__ == "__main__"
                        try:
                            content = file_info["full_path"].read_text(encoding='utf-8')
                            if 'if __name__ == "__main__"' in content or 'def main()' in content:
                                entry_files.append((file_info, score))
                        except:
                            entry_files.append((file_info, score - 1))

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        entry_files.sort(key=lambda x: x[1], reverse=True)
        self.stats["entry_points"] = [f[0]["path"] for f in entry_files[:3]]

    def _detect_framework(self, files: List[Dict]) -> None:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫"""
        framework_signatures = {
            "django": ["manage.py", "urls.py", "settings.py", "wsgi.py"],
            "flask": ["app.py", "flask_app.py", "application.py"],
            "fastapi": ["main.py", "app.py", "fastapi"],
            "streamlit": ["app.py", "streamlit_app.py", "main.py"],
            "pytorch": ["model.py", "train.py", "dataset.py"],
            "tensorflow": ["model.py", "train.py", "tf_"],
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –∏–º–µ–Ω–∞–º —Ñ–∞–π–ª–æ–≤
        file_names = [str(f["path"]).lower() for f in files]
        for framework, signatures in framework_signatures.items():
            for sig in signatures:
                if any(sig in name for name in file_names):
                    self.stats["framework"] = framework
                    return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ Python —Ñ–∞–π–ª–æ–≤
        for file_info in files[:20]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 20 —Ñ–∞–π–ª–æ–≤
            if file_info["is_python"]:
                try:
                    content = file_info["full_path"].read_text(encoding='utf-8', errors='ignore')[:5000]
                    if "import django" in content or "from django" in content:
                        self.stats["framework"] = "django"
                        break
                    elif "import flask" in content or "from flask" in content:
                        self.stats["framework"] = "flask"
                        break
                    elif "import fastapi" in content or "from fastapi" in content:
                        self.stats["framework"] = "fastapi"
                        break
                except:
                    continue

    def _calculate_complexity(self, files: List[Dict]) -> None:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–∞"""
        score = 0

        # –ë–∞–ª–ª—ã –∑–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤
        python_files = [f for f in files if f["is_python"]]
        score += min(len(python_files) * 0.5, 20)

        # –ë–∞–ª–ª—ã –∑–∞ —Ä–∞–∑–º–µ—Ä
        total_py_size = sum(f["size"] for f in python_files)
        score += min(total_py_size / 1024 * 0.1, 30)  # ~10 –±–∞–ª–ª–æ–≤ –∑–∞ 100KB

        # –ë–∞–ª–ª—ã –∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É (–Ω–∞–ª–∏—á–∏–µ –ø–∞–ø–æ–∫)
        dirs = set(str(f["path"].parent) for f in python_files)
        score += min(len(dirs) * 2, 20)

        # –ë–∞–ª–ª—ã –∑–∞ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫
        framework_scores = {
            "django": 15,
            "fastapi": 10,
            "flask": 8,
            "pytorch": 12,
            "tensorflow": 12,
            "streamlit": 5,
            "generic": 0
        }
        score += framework_scores.get(self.stats["framework"], 0)

        self.stats["complexity_score"] = int(score)

    def _build_project_tree(self) -> None:
        """–°—Ç—Ä–æ–∏—Ç –≤–∏–∑—É–∞–ª—å–Ω–æ–µ –¥–µ—Ä–µ–≤–æ –ø—Ä–æ–µ–∫—Ç–∞"""
        tree_lines = []

        def add_to_tree(path: Path, prefix: str = "", is_last: bool = True):
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π —ç–ª–µ–º–µ–Ω—Ç
            name = path.name if path != self.root_dir else self.root_dir.name
            if path.is_dir():
                icon = "üìÅ "
            elif path.suffix == '.py':
                icon = "üêç "
            elif path.suffix in ['.txt', '.md']:
                icon = "üìÑ "
            else:
                icon = "üìù "

            tree_lines.append(f"{prefix}{'‚îî‚îÄ‚îÄ ' if is_last else '‚îú‚îÄ‚îÄ '}{icon}{name}")

            # –ï—Å–ª–∏ —ç—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è, –¥–æ–±–∞–≤–ª—è–µ–º –µ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            if path.is_dir():
                try:
                    items = list(path.iterdir())
                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–∫—Ä—ã—Ç—ã–µ –∏ —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Ñ–∞–π–ª—ã
                    items = [item for item in items
                            if not any(excl in item.name for excl in
                                    ['.git', '__pycache__', '.venv', 'venv', '.idea'])]
                    items.sort(key=lambda x: (not x.is_dir(), x.name.lower()))

                    for i, item in enumerate(items):
                        add_to_tree(item,
                                prefix + ("    " if is_last else "‚îÇ   "),
                                i == len(items) - 1)
                except:
                    pass

        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ
        add_to_tree(self.root_dir)
        self.stats["project_tree"] = tree_lines

class DependencyMapper:
    """–°—Ç—Ä–æ–∏—Ç –∫–∞—Ä—Ç—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏"""

    def __init__(self, root_dir: Path):
        self.root_dir = root_dir
        self.dependency_graph = defaultdict(set)
        self.reverse_dependency = defaultdict(set)
        self.file_contents = {}

    def build_map(self, python_files: List[Path]) -> Dict:
        """–°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
        print("üîó –°—Ç—Ä–æ—é –∫–∞—Ä—Ç—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...")

        # –°–Ω–∞—á–∞–ª–∞ —á–∏—Ç–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
        for file_path in python_files:
            try:
                content = file_path.read_text(encoding='utf-8')
                self.file_contents[file_path] = content
            except:
                continue

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
        for file_path, content in self.file_contents.items():
            imports = self._extract_imports(content, file_path)
            for import_path in imports:
                if import_path:  # –¢–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
                    self.dependency_graph[file_path].add(import_path)
                    self.reverse_dependency[import_path].add(file_path)

        # –ù–∞—Ö–æ–¥–∏–º –∫–æ—Ä–Ω–µ–≤—ã–µ –º–æ–¥—É–ª–∏ (—Ç–µ, –æ—Ç –∫–æ—Ç–æ—Ä—ã—Ö –º–Ω–æ–≥–æ –∑–∞–≤–∏—Å–∏—Ç)
        root_modules = self._find_root_modules()

        return {
            "graph": {str(k): [str(v) for v in vs] for k, vs in self.dependency_graph.items()},
            "reverse": {str(k): [str(v) for v in vs] for k, vs in self.reverse_dependency.items()},
            "root_modules": root_modules,
            "cyclomatic_complexity": self._calculate_cyclomatic_complexity()
        }

    def _extract_imports(self, content: str, file_path: Path) -> Set[Path]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º–ø–æ—Ä—Ç—ã –∏–∑ Python —Ñ–∞–π–ª–∞"""
        imports = set()

        try:
            tree = ast.parse(content)

            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        module_path = self._resolve_import(alias.name, file_path)
                        if module_path:
                            imports.add(module_path)
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        module_path = self._resolve_import(node.module, file_path, node.level)
                        if module_path:
                            imports.add(module_path)
        except:
            # Fallback: –ø—Ä–æ—Å—Ç–æ–π regex –ø–æ–∏—Å–∫
            import_patterns = [
                r'^import\s+(\S+)',
                r'^from\s+(\S+)\s+import',
            ]
            for pattern in import_patterns:
                matches = re.findall(pattern, content, re.MULTILINE)
                for match in matches:
                    module_path = self._resolve_import(match, file_path)
                    if module_path:
                        imports.add(module_path)

        return imports

    def _resolve_import(self, module_name: str, source_file: Path, level: int = 0) -> Optional[Path]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–º–ø–æ—Ä—Ç –≤ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É"""
        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏ –≤–Ω–µ—à–Ω–∏–µ –ø–∞–∫–µ—Ç—ã
        if module_name.split('.')[0] in ['os', 'sys', 'json', 're', 'pathlib', 'typing',
                                        'collections', 'datetime', 'math', 'random']:
            return None

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
        if level > 0:
            parent_dir = source_file.parent
            for _ in range(level - 1):
                parent_dir = parent_dir.parent

            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª
            for suffix in ['', '.py']:
                possible_path = parent_dir / f"{module_name.replace('.', '/')}{suffix}"
                if possible_path.exists():
                    return possible_path

                # –ü—Ä–æ–±—É–µ–º –∫–∞–∫ –ø–∞–∫–µ—Ç (__init__.py)
                init_path = parent_dir / module_name.replace('.', '/') / "__init__.py"
                if init_path.exists():
                    return init_path
        else:
            # –ê–±—Å–æ–ª—é—Ç–Ω—ã–π –∏–º–ø–æ—Ä—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
            for suffix in ['', '.py']:
                possible_path = self.root_dir / f"{module_name.replace('.', '/')}{suffix}"
                if possible_path.exists():
                    return possible_path

                # –ü—Ä–æ–±—É–µ–º –∫–∞–∫ –ø–∞–∫–µ—Ç
                init_path = self.root_dir / module_name.replace('.', '/') / "__init__.py"
                if init_path.exists():
                    return init_path

        return None

    def _find_root_modules(self) -> List[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç –∫–æ—Ä–Ω–µ–≤—ã–µ –º–æ–¥—É–ª–∏ (–Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–µ)"""
        # –ú–æ–¥—É–ª–∏, –æ—Ç –∫–æ—Ç–æ—Ä—ã—Ö –∑–∞–≤–∏—Å—è—Ç –º–Ω–æ–≥–∏–µ –¥—Ä—É–≥–∏–µ
        dependency_scores = {}
        for module, dependents in self.reverse_dependency.items():
            score = len(dependents)
            # –ë–æ–Ω—É—Å –∑–∞ —Ç–æ, —á—Ç–æ —Å–∞–º –º–∞–ª–æ –æ—Ç –∫–æ–≥–æ –∑–∞–≤–∏—Å–∏—Ç
            if module in self.dependency_graph:
                score -= len(self.dependency_graph[module]) * 0.5
            dependency_scores[module] = score

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –≤–∞–∂–Ω–æ—Å—Ç–∏
        sorted_modules = sorted(dependency_scores.items(), key=lambda x: x[1], reverse=True)
        return [str(module) for module, _ in sorted_modules[:10]]

    def _calculate_cyclomatic_complexity(self) -> Dict:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ü–∏–∫–ª–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–∞"""
        complexities = {}

        for file_path, content in self.file_contents.items():
            try:
                # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –≤–µ—Ç–≤–ª–µ–Ω–∏–π
                if_count = content.count(' if ')
                for_count = content.count(' for ')
                while_count = content.count(' while ')
                and_count = content.count(' and ')
                or_count = content.count(' or ')

                complexity = 1 + if_count + for_count + while_count + (and_count + or_count) * 0.5
                complexities[str(file_path)] = int(complexity)
            except:
                complexities[str(file_path)] = 1

        return complexities


class SmartTruncator:
    """–£–º–Ω–æ–µ –æ–±—Ä–µ–∑–∞–Ω–∏–µ –∫–æ–¥–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""

    def __init__(self):
        self.priority_patterns = [
            (r'^import ', 10),           # –ò–º–ø–æ—Ä—Ç—ã - —Å–∞–º—ã–π –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
            (r'^from ', 9),
            (r'^class ', 8),             # –ö–ª–∞—Å—Å—ã
            (r'^def __init__', 7),       # –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä—ã
            (r'^def test_', 6),          # –¢–µ—Å—Ç—ã
            (r'^def ', 5),               # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
            (r'@', 4),                   # –î–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã
            (r'^async def ', 7),         # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
            (r'^    def ', 3),           # –ú–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Å–æ–≤
        ]

    def truncate(self, content: str, max_chars: int, file_type: str = "py") -> Tuple[str, Dict]:
        """–£–º–Ω–æ–µ –æ–±—Ä–µ–∑–∞–Ω–∏–µ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤–∞–∂–Ω—ã—Ö —á–∞—Å—Ç–µ–π"""
        if len(content) <= max_chars:
            return content, {"truncated": False, "original_size": len(content)}

        stats = {
            "truncated": True,
            "original_size": len(content),
            "truncated_size": max_chars,
            "preserved_sections": []
        }

        if file_type == "py":
            return self._truncate_python(content, max_chars, stats)
        elif file_type in ["txt", "md", "rst"]:
            return self._truncate_text(content, max_chars, stats)
        else:
            return content[:max_chars] + f"\n... [–§–ê–ô–õ –û–ë–†–ï–ó–ê–ù: {len(content):,} ‚Üí {max_chars:,} —Å–∏–º–≤–æ–ª–æ–≤] ...", stats

    def _truncate_python(self, content: str, max_chars: int, stats: Dict) -> Tuple[str, Dict]:
        """–£–º–Ω–æ–µ –æ–±—Ä–µ–∑–∞–Ω–∏–µ Python –∫–æ–¥–∞"""
        lines = content.split('\n')
        important_lines = []
        regular_lines = []

        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
        for i, line in enumerate(lines):
            priority = 0
            for pattern, score in self.priority_patterns:
                if re.match(pattern, line.strip()):
                    priority = score
                    break

            if priority >= 5:  # –í—ã—Å–æ–∫–æ–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                important_lines.append((i, line, priority))
            else:
                regular_lines.append((i, line))

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≤–∞–∂–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        important_lines.sort(key=lambda x: x[2], reverse=True)

        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result_lines = []
        preserved_indices = set()

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫ (–æ–±—ã—á–Ω–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –∏–º–ø–æ—Ä—Ç—ã)
        for i in range(min(10, len(lines))):
            result_lines.append(lines[i])
            preserved_indices.add(i)

        # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞–∂–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
        for idx, line, _ in important_lines[:50]:  # –ù–µ –±–æ–ª–µ–µ 50 –≤–∞–∂–Ω—ã—Ö —Å—Ç—Ä–æ–∫
            if idx not in preserved_indices:
                result_lines.append(line)
                preserved_indices.add(idx)

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å—Ç—Ä–æ–∫ (–æ–±—ã—á–Ω–æ —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞)
        for i in range(max(0, len(lines) - 10), len(lines)):
            if i not in preserved_indices:
                result_lines.append(lines[i])
                preserved_indices.add(i)

        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –æ–±—ã—á–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        for idx, line in regular_lines[:30]:  # 30 –æ–±—ã—á–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            if idx not in preserved_indices:
                result_lines.append(line)
                preserved_indices.add(idx)

        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = '\n'.join(result_lines)

        # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ, –æ–±—Ä–µ–∑–∞–µ–º –∂–µ—Å—Ç–∫–æ
        if len(result) > max_chars:
            result = result[:max_chars]

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –æ–±—Ä–µ–∑–∫–∏
        truncation_msg = f"\n\n{'#'*60}\n# –§–ê–ô–õ –û–ë–†–ï–ó–ê–ù –î–õ–Ø –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò\n"
        truncation_msg += f"# –û—Ä–∏–≥–∏–Ω–∞–ª: {len(content):,} —Å–∏–º–≤–æ–ª–æ–≤\n"
        truncation_msg += f"# –ü–æ–∫–∞–∑–∞–Ω–æ: {len(result):,} —Å–∏–º–≤–æ–ª–æ–≤ ({len(result)/len(content)*100:.1f}%)\n"
        truncation_msg += f"# –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(preserved_indices)} –∏–∑ {len(lines)} —Å—Ç—Ä–æ–∫\n"
        truncation_msg += f"{'#'*60}\n"

        result = result[:max_chars - len(truncation_msg)] + truncation_msg

        stats["preserved_lines"] = len(preserved_indices)
        stats["total_lines"] = len(lines)
        stats["preserved_ratio"] = f"{len(preserved_indices)/len(lines)*100:.1f}%"

        return result, stats

    def _truncate_text(self, content: str, max_chars: int, stats: Dict) -> Tuple[str, Dict]:
        """–û–±—Ä–µ–∑–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        # –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –±–µ—Ä–µ–º –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü
        if len(content) <= max_chars:
            return content, stats

        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 70% –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30% –æ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        first_part = int(max_chars * 0.7)
        last_part = max_chars - first_part

        result = content[:first_part]
        result += f"\n\n... [–ø—Ä–æ–ø—É—â–µ–Ω–æ {len(content) - first_part - last_part:,} —Å–∏–º–≤–æ–ª–æ–≤] ...\n\n"
        result += content[-last_part:]

        return result, stats


class EnhancedProjectCollector:
    def __init__(self, root_dir=".", project_name=None):
        self.root_dir = Path(root_dir).resolve()
        self.project_name = project_name or self.root_dir.name

        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ —Å–∞–º–æ–º—É —Å–±–æ—Ä—â–∏–∫—É
        self.collector_path = Path(__file__).resolve()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.analyzer = ProjectAnalyzer(self.root_dir)
        self.truncator = SmartTruncator()
        self.dependency_mapper = None

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ - –¥–æ–±–∞–≤–ª—è–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è —Å–∞–º–æ–≥–æ —Å–±–æ—Ä—â–∏–∫–∞
        self.exclude_dirs = ["venv", "__pycache__", ".venv", ".git",
                            "test", "tests", "docs", "build", "dist",
                            "node_modules", ".pytest_cache", ".mypy_cache", "logs"]

        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è —Å–∫—Ä–∏–ø—Ç–æ–≤ —Å–±–æ—Ä—â–∏–∫–∞
        self.exclude_files = [
            "collect2.py",  # –ò–º—è —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞
        ]

        self.max_sizes = {
            "entry_points": 10000,
            "config_files": 7000,
            "important_modules": 5000,
            "regular_modules": 2000,
            "text_files": 2000,
            "data_files": 1000,
        }

    def collect_enhanced(self) -> str:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —Å–±–æ—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞"""
        print(f"üöÄ –ó–∞–ø—É—Å–∫–∞—é —É–ª—É—á—à–µ–Ω–Ω—ã–π —Å–±–æ—Ä—â–∏–∫ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞: {self.project_name}")

        # 1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç
        stats = self.analyzer.analyze()

        # 2. –°–æ–±–∏—Ä–∞–µ–º Python —Ñ–∞–π–ª—ã
        python_files = self._collect_python_files()

        # 3. –°—Ç—Ä–æ–∏–º –∫–∞—Ä—Ç—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        self.dependency_mapper = DependencyMapper(self.root_dir)
        dependency_map = self.dependency_mapper.build_map(python_files)

        # 4. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        output_file = self._generate_report(stats, dependency_map, python_files)

        return output_file

    def _collect_python_files(self) -> List[Path]:
        """–°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ Python —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞, –∏—Å–∫–ª—é—á–∞—è —Å–∞–º —Å–±–æ—Ä—â–∏–∫"""
        python_files = []
        for path in self.root_dir.rglob("*.py"):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–∫–ª—é—á–∞–µ–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            if any(excl in str(path) for excl in self.exclude_dirs):
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª —Å–∞–º–∏–º —Å–±–æ—Ä—â–∏–∫–æ–º
            if self._is_collector_file(path):
                continue

            python_files.append(path)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ (—Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞ –ø–µ—Ä–≤—ã–º–∏)
        entry_points = self.analyzer.stats["entry_points"]
        def sort_key(path):
            rel_path = path.relative_to(self.root_dir)
            if str(rel_path) in entry_points:
                return (0, entry_points.index(str(rel_path)))
            elif "test" in str(rel_path).lower():
                return (2, str(rel_path))
            else:
                return (1, str(rel_path))

        python_files.sort(key=sort_key)
        return python_files

    def _is_collector_file(self, path: Path) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª —Å–±–æ—Ä—â–∏–∫–æ–º"""
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –ø—É—Ç–µ–º –∫ —Ç–µ–∫—É—â–µ–º—É —Ñ–∞–π–ª—É
        try:
            if path.resolve() == self.collector_path:
                return True
        except:
            pass

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        filename = path.name
        if filename in self.exclude_files:
            return True

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É (–µ—Å–ª–∏ —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã —Å–±–æ—Ä—â–∏–∫–∞)
        try:
            content = path.read_text(encoding='utf-8', errors='ignore')[:1000]
            collector_keywords = [
                "class EnhancedProjectCollector",
                "class ProjectAnalyzer",
                "class SmartTruncator",
                "—Å–±–æ—Ä—â–∏–∫ –ø—Ä–æ–µ–∫—Ç–∞",
                "collect_enhanced",
                "ProjectCollector",
            ]
            if any(keyword in content for keyword in collector_keywords):
                return True
        except:
            pass

        return False

    def _generate_report(self, stats: Dict, dependency_map: Dict, python_files: List[Path]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç"""
        output_file = f"enhanced_project_report_{self.project_name}.txt"
        content = []

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        content.append(f"{'='*80}")
        content.append(f"–£–õ–£–ß–®–ï–ù–ù–´–ô –û–¢–ß–ï–¢ –ü–†–û–ï–ö–¢–ê: {self.project_name}")
        content.append(f"{'='*80}\n")

        # 1. –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        content.append(self._generate_summary_section(stats))

        # 2. –ö–∞—Ä—Ç–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        content.append(self._generate_dependency_section(dependency_map))

        # 3. –ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        content.append(self._generate_complexity_section(stats, dependency_map))

        # 4. –¢–æ—á–∫–∏ –≤—Ö–æ–¥–∞
        content.append(self._generate_entry_points_section(stats, python_files))

        # 5. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        content.append(self._generate_config_section())

        # 6. –ö–ª—é—á–µ–≤—ã–µ –º–æ–¥—É–ª–∏ (–Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)
        content.append(self._generate_key_modules_section(dependency_map, python_files))

        # 7. –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã (–∫—Ä–∞—Ç–∫–æ)
        content.append(self._generate_other_files_section())

        # 8. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        content.append(self._generate_recommendations_section(stats, dependency_map))

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∞–π–ª
        full_content = '\n'.join(content)
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(full_content)

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self._print_final_stats(output_file, full_content, stats)

        return output_file

    def _generate_summary_section(self, stats: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞–∑–¥–µ–ª —Å –æ–±—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
        section = []
        section.append(f"{'üìä –û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ü–†–û–ï–ö–¢–ï':^80}")
        section.append(f"{'‚îÄ'*80}")

        section.append(f"üìÅ –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞: {self.project_name}")
        section.append(f"üìÇ –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {self.root_dir}")
        section.append(f"üìà –û–±—ä–µ–º –ø—Ä–æ–µ–∫—Ç–∞: {stats['total_size'] / 1024:.1f} KB")
        section.append(f"üìÑ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {stats['total_files']}")
        section.append(f"üêç Python —Ñ–∞–π–ª–æ–≤: {stats['python_files_count']}")
        section.append(f"üìä –°—Ç—Ä–æ–∫ –∫–æ–¥–∞ (Python): {stats['total_code_lines']:,}".replace(',', ' '))
        section.append(f"üìà –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {stats['total_code_lines'] / max(1, stats['python_files_count']):.1f} —Å—Ç—Ä–æ–∫ –Ω–∞ —Ñ–∞–π–ª")

        # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω Python —Ñ–∞–π–ª
        if stats['python_files_count'] > 0:
            section.append(f"üìê –ü–ª–æ—Ç–Ω–æ—Å—Ç—å –∫–æ–¥–∞: {stats['total_code_lines'] / max(1, stats['total_size']/1024):.1f} —Å—Ç—Ä–æ–∫/KB")

        section.append(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫: {stats['framework'].upper()}")
        section.append(f"‚ö° –û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: {stats['complexity_score']}/100")

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤
        section.append(f"\nüìã –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –ø–æ —Ç–∏–ø–∞–º:")
        for ext, count in sorted(stats['file_types'].items(), key=lambda x: x[1], reverse=True)[:10]:
            if ext:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
                section.append(f"  {ext or '–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è'}: {count} —Ñ–∞–π–ª–æ–≤")

        # –¢–æ–ø —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å Python —Ñ–∞–π–ª—ã)
        if stats.get('files_most_lines') and len(stats['files_most_lines']) > 0:
            section.append(f"\nüìà –¢–æ–ø-5 —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞:")
            for i, file_info in enumerate(stats['files_most_lines'][:5], 1):
                section.append(f"  {i}. {file_info['path']}: {file_info['lines']:,} —Å—Ç—Ä–æ–∫".replace(',', ' '))

        # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if stats.get('average_complexity'):
            section.append(f"\nüî¨ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:")
            section.append(f"  –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {stats['average_complexity']:.2f}")
        if stats.get('total_functions'):
            section.append(f"  –í—Å–µ–≥–æ —Ñ—É–Ω–∫—Ü–∏–π: {stats['total_functions']}")

        section.append(f"\n")
        return '\n'.join(section)

    def _generate_dependency_section(self, dependency_map: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞–∑–¥–µ–ª —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π –ø—Ä–æ–µ–∫—Ç–∞"""
        section = []
        section.append(f"{'üå≥ –í–ò–ó–£–ê–õ–¨–ù–û–ï –î–ï–†–ï–í–û –ü–†–û–ï–ö–¢–ê':^80}")
        section.append(f"{'‚îÄ'*80}")

        # –í—ã–≤–æ–¥–∏–º –¥–µ—Ä–µ–≤–æ –ø—Ä–æ–µ–∫—Ç–∞
        project_tree = self.analyzer.stats.get("project_tree", [])
        if project_tree:
            section.append("\nüìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–∞—Ç–∞–ª–æ–≥–æ–≤:")
            section.extend(project_tree)
        else:
            section.append("\n‚ö†Ô∏è  –î–µ—Ä–µ–≤–æ –ø—Ä–æ–µ–∫—Ç–∞ –Ω–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–æ")

        # –û—Å—Ç–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—ã–µ –º–æ–¥—É–ª–∏
        root_modules = dependency_map.get('root_modules', [])
        if root_modules:
            section.append(f"\n\nüéØ –ö–û–†–ù–ï–í–´–ï –ú–û–î–£–õ–ò (—Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ):")
            for i, module in enumerate(root_modules[:10], 1):
                section.append(f"  {i:2d}. {module}")

        section.append(f"\n")
        return '\n'.join(section)

    def _generate_complexity_section(self, stats: Dict, dependency_map: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞–∑–¥–µ–ª —Å –∞–Ω–∞–ª–∏–∑–æ–º —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""
        section = []
        section.append(f"{'‚öôÔ∏è  –ê–ù–ê–õ–ò–ó –°–õ–û–ñ–ù–û–°–¢–ò –ü–†–û–ï–ö–¢–ê':^80}")
        section.append(f"{'‚îÄ'*80}")

        complexities = dependency_map.get('cyclomatic_complexity', {})
        if complexities:
            # –°–∞–º—ã–µ —Å–ª–æ–∂–Ω—ã–µ —Ñ–∞–π–ª—ã
            section.append(f"\nüî¥ –°–ê–ú–´–ï –°–õ–û–ñ–ù–´–ï –§–ê–ô–õ–´:")
            sorted_complex = sorted(complexities.items(), key=lambda x: x[1], reverse=True)[:5]
            for file_path, complexity in sorted_complex:
                filename = Path(file_path).name
                section.append(f"  üìÑ {filename}: {complexity} –±–∞–ª–ª–æ–≤ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        score = stats['complexity_score']
        section.append(f"\nüí° –í–´–í–û–î–´:")
        if score < 30:
            section.append(f"  ‚úÖ –ü—Ä–æ–µ–∫—Ç –ø—Ä–æ—Å—Ç–æ–π, –º–æ–∂–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ü–µ–ª–∏–∫–æ–º")
        elif score < 60:
            section.append(f"  ‚ö†Ô∏è  –ü—Ä–æ–µ–∫—Ç —Å—Ä–µ–¥–Ω–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏, —Ñ–æ–∫—É—Å–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ –∫–æ—Ä–Ω–µ–≤—ã—Ö –º–æ–¥—É–ª—è—Ö")
        else:
            section.append(f"  üî¥ –ü—Ä–æ–µ–∫—Ç —Å–ª–æ–∂–Ω—ã–π, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –ø–æ —á–∞—Å—Ç—è–º")

        section.append(f"\n")
        return '\n'.join(section)

    def _generate_entry_points_section(self, stats: Dict, python_files: List[Path]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞–∑–¥–µ–ª —Å —Ç–æ—á–∫–∞–º–∏ –≤—Ö–æ–¥–∞"""
        section = []
        section.append(f"{'üéØ –¢–û–ß–ö–ò –í–•–û–î–ê –í –ü–†–û–ï–ö–¢':^80}")
        section.append(f"{'‚îÄ'*80}")

        if stats['entry_points']:
            for entry_point in stats['entry_points'][:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ 3 —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞
                entry_path = self.root_dir / entry_point
                if entry_path.exists():
                    try:
                        content = entry_path.read_text(encoding='utf-8')
                        truncated, trunc_stats = self.truncator.truncate(
                            content, self.max_sizes['entry_points'], "py"
                        )

                        section.append(f"\nüìÑ {entry_point}:")
                        section.append(f"{'‚îÄ'*40}")
                        section.append(truncated)
                        section.append(f"{'‚îÄ'*40}")

                        if trunc_stats.get('truncated'):
                            section.append(f"‚ö†Ô∏è  –ü–æ–∫–∞–∑–∞–Ω–æ {trunc_stats['truncated_size']:,} –∏–∑ {trunc_stats['original_size']:,} —Å–∏–º–≤–æ–ª–æ–≤")
                    except Exception as e:
                        section.append(f"\n‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {entry_point}: {str(e)}")
        else:
            section.append(f"\n‚ö†Ô∏è  –¢–æ—á–∫–∏ –≤—Ö–æ–¥–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã:")
            for file_path in python_files[:2]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2 —Ñ–∞–π–ª–∞ –∫–∞–∫ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞
                rel_path = file_path.relative_to(self.root_dir)
                section.append(f"  üìÑ {rel_path}")

        section.append(f"\n")
        return '\n'.join(section)

    def _generate_config_section(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞–∑–¥–µ–ª —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏"""
        section = []
        section.append(f"{'‚öôÔ∏è  –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–û–ù–ù–´–ï –§–ê–ô–õ–´':^80}")
        section.append(f"{'‚îÄ'*80}")

        config_files = [
            "requirements.txt", "setup.py", "pyproject.toml",
            "config.py", "settings.py", ".env", "dockerfile", "docker-compose.yml",
            "README.md", "README.rst", "MANIFEST.in"
        ]

        found_configs = []
        for config_file in config_files:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å —Ä–∞–∑–Ω—ã–º–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞–º–∏ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏
            for path in self.root_dir.glob(f"**/{config_file}"):
                if any(excl in str(path) for excl in self.exclude_dirs):
                    continue
                found_configs.append(path)

        if found_configs:
            for config_path in found_configs[:5]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 5 —Ñ–∞–π–ª–∞–º–∏
                rel_path = config_path.relative_to(self.root_dir)
                try:
                    content = config_path.read_text(encoding='utf-8', errors='ignore')
                    max_size = self.max_sizes.get('config_files', 2000)

                    if len(content) > max_size:
                        content = content[:max_size] + f"\n... [–æ–±—Ä–µ–∑–∫–∞: {len(content):,} ‚Üí {max_size:,} —Å–∏–º–≤–æ–ª–æ–≤]"

                    section.append(f"\nüìÑ {rel_path}:")
                    section.append(f"{'‚îÄ'*40}")
                    section.append(content[:500])  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤
                    section.append(f"{'‚îÄ'*40}")
                except Exception as e:
                    section.append(f"\nüìÑ {rel_path}: [–§–∞–π–ª –ø—Ä–æ–ø—É—â–µ–Ω: {str(e)}]")
        else:
            section.append(f"\n‚ö†Ô∏è  –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        section.append(f"\n")
        return '\n'.join(section)

    def _generate_key_modules_section(self, dependency_map: Dict, python_files: List[Path]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞–∑–¥–µ–ª —Å –∫–ª—é—á–µ–≤—ã–º–∏ –º–æ–¥—É–ª—è–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
        section = []
        section.append(f"{'üîë –ö–õ–Æ–ß–ï–í–´–ï –ú–û–î–£–õ–ò (–Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)':^80}")
        section.append(f"{'‚îÄ'*80}")

        root_modules = dependency_map.get('root_modules', [])
        key_files = []

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—É—Ç–∏ –º–æ–¥—É–ª–µ–π –≤ –æ–±—ä–µ–∫—Ç—ã Path
        for module in root_modules[:15]:  # –ë–µ—Ä–µ–º –¥–æ 15 –∫–ª—é—á–µ–≤—ã—Ö –º–æ–¥—É–ª–µ–π
            try:
                module_path = Path(module)
                if module_path.exists():
                    key_files.append(module_path)
            except:
                pass

        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç –≤ –∫–ª—é—á–µ–≤—ã—Ö
        entry_points = [self.root_dir / ep for ep in self.analyzer.stats['entry_points']]
        for ep in entry_points:
            if ep.exists() and ep not in key_files:
                key_files.append(ep)

        if key_files:
            section.append(f"\nüéØ –û—Ç–æ–±—Ä–∞–Ω–æ {len(key_files)} –∫–ª—é—á–µ–≤—ã—Ö –º–æ–¥—É–ª–µ–π:")

            for i, file_path in enumerate(key_files[:10], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                rel_path = file_path.relative_to(self.root_dir)
                try:
                    content = file_path.read_text(encoding='utf-8')

                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞–∂–Ω–æ—Å—Ç–∏
                    if file_path in entry_points:
                        max_size = self.max_sizes['important_modules']
                    else:
                        max_size = self.max_sizes['regular_modules']

                    truncated, trunc_stats = self.truncator.truncate(content, max_size, "py")

                    section.append(f"\n{i:2d}. üìÑ {rel_path}")
                    section.append(f"{'‚îÄ'*40}")
                    section.append(truncated)
                    section.append(f"{'‚îÄ'*40}")

                    if trunc_stats.get('truncated'):
                        section.append(f"üìä –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {trunc_stats.get('preserved_lines', '?')} —Å—Ç—Ä–æ–∫ ({trunc_stats.get('preserved_ratio', '?')})")

                except Exception as e:
                    section.append(f"\n{i:2d}. üìÑ {rel_path}: [–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è: {str(e)}]")

            if len(key_files) > 10:
                section.append(f"\nüìã ... –∏ –µ—â–µ {len(key_files) - 10} –∫–ª—é—á–µ–≤—ã—Ö –º–æ–¥—É–ª–µ–π")
        else:
            section.append(f"\n‚ö†Ô∏è  –ö–ª—é—á–µ–≤—ã–µ –º–æ–¥—É–ª–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã, –ø–æ–∫–∞–∑—ã–≤–∞—é –ø–µ—Ä–≤—ã–µ 5 Python —Ñ–∞–π–ª–æ–≤:")
            for i, file_path in enumerate(python_files[:5], 1):
                rel_path = file_path.relative_to(self.root_dir)
                section.append(f"  {i:2d}. {rel_path}")

        section.append(f"\n")
        return '\n'.join(section)

    def _generate_other_files_section(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞–∑–¥–µ–ª —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏, –∏—Å–∫–ª—é—á–∞—è —Å–±–æ—Ä—â–∏–∫"""
        section = []
        section.append(f"{'üìÅ –ü–†–û–ß–ò–ï –§–ê–ô–õ–´ –ü–†–û–ï–ö–¢–ê':^80}")
        section.append(f"{'‚îÄ'*80}")

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã (–∫—Ä–æ–º–µ —É–∂–µ –ø–æ–∫–∞–∑–∞–Ω–Ω—ã—Ö –∏ —Å–±–æ—Ä—â–∏–∫–∞)
        all_files = []
        for path in self.root_dir.rglob("*"):
            if path.is_file() and not any(excl in str(path) for excl in self.exclude_dirs):
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º Python —Ñ–∞–π–ª—ã, –æ–Ω–∏ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
                if path.suffix.lower() == '.py':
                    continue

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª —Å–±–æ—Ä—â–∏–∫–∞
                if self._is_collector_file(path):
                    continue

                all_files.append(path)

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º
        file_groups = defaultdict(list)
        for file_path in all_files[:100]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 100 —Ñ–∞–π–ª–∞–º–∏
            ext = file_path.suffix.lower()
            file_groups[ext or '–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è'].append(file_path)

        section.append(f"\nüìä –í—Å–µ–≥–æ –ø—Ä–æ—á–∏—Ö —Ñ–∞–π–ª–æ–≤: {len(all_files)}")
        section.append(f"üìã –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø–∞–º:\n")

        for ext, files in sorted(file_groups.items()):
            if ext in ['.pyc', '.pyo', '.so', '.dll']:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–∏–Ω–∞—Ä–Ω—ã–µ —Ñ–∞–π–ª—ã
                continue

            section.append(f"  {ext or '–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è'}: {len(files)} —Ñ–∞–π–ª–æ–≤")
            for file_path in files[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ 3 —Ñ–∞–π–ª–∞ –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞
                rel_path = file_path.relative_to(self.root_dir)
                section.append(f"      üìÑ {rel_path}")
            if len(files) > 3:
                section.append(f"      ... –∏ –µ—â–µ {len(files) - 3} —Ñ–∞–π–ª–æ–≤")

        section.append(f"\n")
        return '\n'.join(section)

    def _generate_recommendations_section(self, stats: Dict, dependency_map: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        section = []
        section.append(f"{'üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê –ù–ï–ô–†–û–°–ï–¢–¨–Æ':^80}")
        section.append(f"{'‚îÄ'*80}")

        framework = stats['framework']
        complexity = stats['complexity_score']

        section.append(f"\nüéØ –°–¢–†–ê–¢–ï–ì–ò–Ø –ê–ù–ê–õ–ò–ó–ê:")

        if framework == "django":
            section.append(f"  1. –ù–∞—á–Ω–∏—Ç–µ —Å settings.py –∏ urls.py")
            section.append(f"  2. –ò–∑—É—á–∏—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –≤ –ø–∞–ø–∫–µ apps/")
            section.append(f"  3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ models.py –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
            section.append(f"  4. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ views.py –∏ —Ñ–æ—Ä–º—ã")
        elif framework == "flask":
            section.append(f"  1. –ò–∑—É—á–∏—Ç–µ app.py –∏–ª–∏ application.py")
            section.append(f"  2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É Blueprints")
            section.append(f"  3. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –º–æ–¥–µ–ª–∏ –∏ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
        elif framework == "fastapi":
            section.append(f"  1. –ù–∞—á–Ω–∏—Ç–µ —Å main.py –∏ —Ä–æ—É—Ç–µ—Ä–æ–≤")
            section.append(f"  2. –ò–∑—É—á–∏—Ç–µ —Å—Ö–µ–º—ã Pydantic –≤ schemas/")
            section.append(f"  3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤ dependencies/")
        else:
            section.append(f"  1. –ù–∞—á–Ω–∏—Ç–µ —Å —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞ (—Å–º. –≤—ã—à–µ)")
            section.append(f"  2. –ò–∑—É—á–∏—Ç–µ –∫–æ—Ä–Ω–µ–≤—ã–µ –º–æ–¥—É–ª–∏ –∏–∑ –∫–∞—Ä—Ç—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π")
            section.append(f"  3. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã")

        section.append(f"\nüîç –§–û–ö–£–° –ù–ê:")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        if complexity > 70:
            section.append(f"  ‚Ä¢ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã")
            section.append(f"  ‚Ä¢ –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –º–µ–∂–¥—É –º–æ–¥—É–ª—è–º–∏")
            section.append(f"  ‚Ä¢ –û—Å–Ω–æ–≤–Ω—ã–µ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏")
        elif complexity > 40:
            section.append(f"  ‚Ä¢ –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
            section.append(f"  ‚Ä¢ –ö–ª—é—á–µ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –∫–ª–∞—Å—Å—ã")
            section.append(f"  ‚Ä¢ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞")
        else:
            section.append(f"  ‚Ä¢ –ü–æ–ª–Ω—ã–π –∫–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞")
            section.append(f"  ‚Ä¢ –í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏")
            section.append(f"  ‚Ä¢ –¢–µ—Å—Ç—ã –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è")

        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        root_modules = dependency_map.get('root_modules', [])
        if root_modules:
            section.append(f"\nüéØ –ü–†–ò–û–†–ò–¢–ï–¢–ù–´–ï –ú–û–î–£–õ–ò:")
            for i, module in enumerate(root_modules[:5], 1):
                module_name = Path(module).name
                section.append(f"  {i}. {module_name}")

        section.append(f"\n‚ö†Ô∏è  –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø:")
        section.append(f"  ‚Ä¢ Python —Ñ–∞–π–ª—ã –æ–±—Ä–µ–∑–∞–Ω—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
        section.append(f"  ‚Ä¢ –ü–æ–∫–∞–∑–∞–Ω—ã —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –º–æ–¥—É–ª–∏")
        section.append(f"  ‚Ä¢ –ù–µ—Ç –±–∏–Ω–∞—Ä–Ω—ã—Ö –∏ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")

        section.append(f"\n{'='*80}")
        section.append(f"üìÖ –û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {self._get_timestamp()}")
        section.append(f"{'='*80}")

        return '\n'.join(section)

    def _get_timestamp(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def _print_final_stats(self, output_file: str, content: str, stats: Dict) -> None:
        """–í—ã–≤–æ–¥–∏—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        print(f"\n{'='*60}")
        print(f"‚úÖ –£–õ–£–ß–®–ï–ù–ù–´–ô –û–¢–ß–ï–¢ –°–û–ó–î–ê–ù!")
        print(f"{'='*60}")
        print(f"üìÅ –ü—Ä–æ–µ–∫—Ç: {self.project_name}")
        print(f"üìÑ –§–∞–π–ª –æ—Ç—á–µ—Ç–∞: {output_file}")
        print(f"üìä –†–∞–∑–º–µ—Ä –æ—Ç—á–µ—Ç–∞: {len(content):,} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"üêç Python —Ñ–∞–π–ª–æ–≤: {stats['file_types'].get('.py', 0)}")
        print(f"üéØ –§—Ä–µ–π–º–≤–æ—Ä–∫: {stats['framework']}")
        print(f"‚ö° –°–ª–æ–∂–Ω–æ—Å—Ç—å: {stats['complexity_score']}/100")
        print(f"üîó –ö–æ—Ä–Ω–µ–≤—ã—Ö –º–æ–¥—É–ª–µ–π: {len(stats.get('entry_points', []))}")
        print(f"{'='*60}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞"""
    import argparse

    parser = argparse.ArgumentParser(description='–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–±–æ—Ä—â–∏–∫ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π')
    parser.add_argument('--path', default='.', help='–ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: —Ç–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è)')
    parser.add_argument('--name', help='–ò–º—è –ø—Ä–æ–µ–∫—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –∏–º—è –ø–∞–ø–∫–∏)')
    parser.add_argument('--output', help='–ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞')

    args = parser.parse_args()

    # –°–æ–∑–¥–∞–µ–º —Å–±–æ—Ä—â–∏–∫
    collector = EnhancedProjectCollector(root_dir=args.path, project_name=args.name)

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–±–æ—Ä–∫—É
    output_file = collector.collect_enhanced()

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å
    abs_path = Path(output_file).resolve()
    print(f"\nüìã –§–ê–ô–õ –°–û–•–†–ê–ù–ï–ù: {abs_path}")
    print(f"\n‚ú® –ì–æ—Ç–æ–≤–æ! –ü—Ä–æ–µ–∫—Ç —Å–æ–±—Ä–∞–Ω –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()